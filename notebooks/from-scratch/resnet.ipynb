{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet\n",
    "\n",
    "\n",
    "Original paper: [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "![resnet](https://miro.medium.com/v2/resize:fit:1400/1*tFlMRm_wjBDrgOQMhEM0cQ.png)\n",
    "\n",
    "The ResNet50 architecture is a variant of the ResNet (Residual Network) architecture, which is known for its ability to train very deep neural networks effectively. ResNet50 specifically has 50 layers (hence the name) and is widely used for tasks like image classification. Here's a detailed rundown of its architecture:\n",
    "\n",
    "1. **Input Layer**: This layer takes as input the image data, typically represented as a three-dimensional array of pixel values (height, width, channels).\n",
    "\n",
    "2. **Initial Convolutional Layer**: The input image passes through an initial convolutional layer with 64 filters (also known as kernels or feature detectors) of size 7x7. This layer is followed by batch normalization and ReLU activation.\n",
    "\n",
    "3. **Pooling Layer**: After the initial convolution, a max-pooling layer with a 3x3 filter and a stride of 2 is applied to downsample the spatial dimensions of the feature maps.\n",
    "\n",
    "4. **Residual Blocks**: ResNet50 consists of several residual blocks, each containing multiple convolutional layers. The key idea behind a residual block is the introduction of skip connections (also called shortcut connections) that bypass one or more convolutional layers. This allows for easier training of deep networks by mitigating the vanishing gradient problem. ResNet50 includes several of these blocks stacked on top of each other.\n",
    "\n",
    "5. **Global Average Pooling**: Towards the end of the network, after several residual blocks, global average pooling is applied to reduce the spatial dimensions of the feature maps to 1x1. This operation calculates the average value of each feature map, resulting in a fixed-size vector regardless of the input image size.\n",
    "\n",
    "6. **Fully Connected Layer**: Following global average pooling, a fully connected layer is used for classification. In ResNet50, this layer has 1000 units corresponding to the 1000 ImageNet classes.\n",
    "\n",
    "7. **Softmax Activation**: The output of the fully connected layer is passed through a softmax activation function, which converts the raw scores into probabilities, indicating the likelihood of each class.\n",
    "\n",
    "8. **Output Layer**: The final output layer presents the predicted probabilities for each class in the classification task.\n",
    "\n",
    "Overall, ResNet50's architecture is characterized by its deep structure, residual blocks, and skip connections, which allow it to effectively learn features from images and achieve state-of-the-art performance in various computer vision tasks.\n",
    "\n",
    "## [TODO do the 1.5 archi](https://catalog.ngc.nvidia.com/orgs/nvidia/resources/resnet_50_v1_5_for_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "[Dataset Card](https://huggingface.co/datasets/bastienp/visible-watermark-pita)\n",
    "\n",
    "In this notebook we will use the pita-watermark dataset which conatins images of the coco dataset that has watermarks added on top of them. \n",
    "\n",
    "The goal is to:\n",
    "- Detect watermarks \n",
    "- Remove watermarks \n",
    "\n",
    "\n",
    "#### TOOD: specify goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Import torch dataset and create custom dataset that loads the data\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "class WatermarkDataset(Dataset):\n",
    "    def __init__(self, name=\"visible_watermark_pita\", split=\"train\", transform=None):\n",
    "        self.name = name\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.data = pd.read_csv(f\"{name}/{split}.csv\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = os.path.join(self.name, self.split , str(self.data.iloc[idx][\"image_id\"]) + \".png\")\n",
    "        image = Image.open(img_name)\n",
    "        label = self.data.iloc[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label[\"category_id\"]\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.name} - {self.split}: {len(self.data)}\\n {self.data.head()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WatermarkDataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * 4, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * 4)\n",
    "        \n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels * 4:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * 4, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * 4)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        identity = self.downsample(identity)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet50(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, 7, 2, 3, bias=False)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(64)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.maxpool = torch.nn.MaxPool2d(2, 2)\n",
    "    \n",
    "        self.residuals = torch.nn.Sequential(\n",
    "            # 3x3 conv, 64 filters, stride 1, times 3\n",
    "            ResidualBlock(in_channels=64, out_channels=64),\n",
    "            ResidualBlock(in_channels=256, out_channels=64),\n",
    "            ResidualBlock(in_channels=256, out_channels=64, stride=2),\n",
    "\n",
    "            # 3x3 conv, 128 filters, stride 2, times 4\n",
    "            ResidualBlock(in_channels=256, out_channels=128),\n",
    "            ResidualBlock(in_channels=512, out_channels=128),\n",
    "            ResidualBlock(in_channels=512, out_channels=128),\n",
    "            ResidualBlock(in_channels=512, out_channels=256),\n",
    "\n",
    "            # 3x3 conv, 256 filters, stride 2, times 6\n",
    "            ResidualBlock(in_channels=1024, out_channels=256, stride=2),\n",
    "            ResidualBlock(in_channels=1024, out_channels=256),\n",
    "            ResidualBlock(in_channels=1024, out_channels=256),\n",
    "            ResidualBlock(in_channels=1024, out_channels=256),\n",
    "            ResidualBlock(in_channels=1024, out_channels=256),\n",
    "            ResidualBlock(in_channels=1024, out_channels=512),\n",
    "\n",
    "            # 3x3 conv, 512 filters, stride 2, times 3\n",
    "            ResidualBlock(in_channels=2048, out_channels=512, stride=2),\n",
    "            ResidualBlock(in_channels=2048, out_channels=512),\n",
    "            ResidualBlock(in_channels=2048, out_channels=512),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = torch.nn.Linear(2048, num_classes) # TODO: Change fc size to same as paper\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.residuals(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1) # TODO: Change flqtten to conv layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = Resnet50(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import summary from torchsummary and print the model summary\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Import a torch resnt50 and print its summary\n",
    "import torchvision.models as models\n",
    "resnet50 = models.resnet50(pretrained=False)\n",
    "summary(resnet50, (3, 224, 224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load imqge\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg\"\n",
    "im = Image.open(requests.get(url, stream=True).raw)\n",
    "# im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "from torchvision import transforms\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "im = preprocess(im)\n",
    "im = im.unsqueeze(0)\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(im)\n",
    "    prediction = torch.nn.functional.softmax(prediction[0], dim=0)\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train to classify watermarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom training loop\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 48\n",
    "\n",
    "# Preprocess the images\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    # transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# Load the dataset\n",
    "train_dataset = WatermarkDataset(split=\"train\", transform=preprocess)\n",
    "val_dataset = WatermarkDataset(split=\"val\", transform=preprocess)\n",
    "test_dataset = WatermarkDataset(split=\"test\", transform=preprocess)\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Create the model\n",
    "model = Resnet50(2)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training step\n",
    "def train_step(model, input, target, criterion, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "# Validation step\n",
    "def val_step(model, input, target, criterion):\n",
    "    output = model(input)\n",
    "    loss = criterion(output, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "model.to(device)\n",
    "\n",
    "def train(num_epochs, train_loader, val_loader, model, criterion, optimizer, device):\n",
    "    losses, val_losses = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            inputs, targets = data\n",
    "            inputs = inputs.float().view(-1, 3, 256, 256).to(device)\n",
    "            targets = F.one_hot(targets - 1, num_classes=2).float().to(device)\n",
    "            loss = train_step(model, inputs, targets, criterion, optimizer)\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, loss: {running_loss/len(train_loader)}\")\n",
    "        losses.append(running_loss/len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        for i, data in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "            inputs, targets = data\n",
    "            inputs = inputs.float().view(-1, 3, 256, 256).to(device)\n",
    "            targets = F.one_hot(targets - 1, num_classes=2).float().to(device)\n",
    "            loss = val_step(model, inputs, targets, criterion)\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Validation loss: {running_loss/len(val_loader)}\")\n",
    "        val_losses.append(running_loss/len(val_loader))\n",
    "    \n",
    "    return model, losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "\n",
    "model, losses, val_losses = train(num_epochs, train_loader, val_loader, model, criterion, optimizer, device)\n",
    "losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the losses\n",
    "plt.plot(losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy ON VAL SET PLEASE FIXME to test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, total=len(test_loader)):\n",
    "        images, labels = data\n",
    "        images = images.float().view(-1, 3, 256, 256).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == (labels - 1)).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"resnet50.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
